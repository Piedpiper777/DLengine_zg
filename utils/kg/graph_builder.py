"""
çŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—
ç”¨äºä»æ–‡æ¡£æ–‡æœ¬ä¸­æå–çŸ¥è¯†å¹¶æ„å»ºå›¾è°±
"""

import os
import json
import re
import uuid
import sqlite3
from datetime import datetime
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from py2neo import Graph
import docx

from utils.llm.llm_client import llm_client

# ==================== æ•°æ®æ¨¡å‹å®šä¹‰ ====================

class Property(BaseModel):
    """çŸ¥è¯†å›¾è°±ä¸­çš„å±æ€§ï¼Œç”±é”®å’Œå€¼ç»„æˆ"""
    key: str = Field(..., description="å±æ€§çš„é”®å")
    value: str = Field(..., description="å±æ€§çš„å€¼")

class Node(BaseModel):
    """çŸ¥è¯†å›¾è°±ä¸­çš„èŠ‚ç‚¹ï¼Œä»£è¡¨å®ä½“"""
    id: str = Field(..., description="èŠ‚ç‚¹å”¯ä¸€æ ‡è¯†ç¬¦")
    type: str = Field(..., description="èŠ‚ç‚¹ç±»å‹")
    properties: Optional[List[Property]] = Field(
        None, description="èŠ‚ç‚¹å±æ€§åˆ—è¡¨"
    )

class Relationship(BaseModel):
    """çŸ¥è¯†å›¾è°±ä¸­çš„å…³ç³»ï¼Œè¿æ¥ä¸¤ä¸ªèŠ‚ç‚¹"""
    source: Node = Field(..., description="å…³ç³»çš„èµ·å§‹èŠ‚ç‚¹")
    target: Node = Field(..., description="å…³ç³»çš„ç›®æ ‡èŠ‚ç‚¹")
    type: str = Field(..., description="å…³ç³»ç±»å‹")
    properties: Optional[List[Property]] = Field(
        None, description="å…³ç³»å±æ€§åˆ—è¡¨"
    )

class KnowledgeGraph(BaseModel):
    """å®Œæ•´çš„çŸ¥è¯†å›¾è°±ç»“æ„"""
    nodes: List[Node] = Field(..., description="å›¾è°±ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹")
    rels: List[Relationship] = Field(..., description="å›¾è°±ä¸­çš„æ‰€æœ‰å…³ç³»")

# ==================== è¾…åŠ©å‡½æ•° ====================

def format_property_key(s: str) -> str:
    """æ ¼å¼åŒ–å±æ€§é”®åï¼Œè½¬æ¢ä¸ºé©¼å³°å‘½å"""
    words = s.split()
    if not words:
        return s
    first_word = words[0].lower()
    capitalized_words = [word.capitalize() for word in words[1:]]
    return "".join([first_word] + capitalized_words)

def props_to_dict(props) -> dict:
    """å°†å±æ€§åˆ—è¡¨è½¬æ¢ä¸ºå­—å…¸"""
    properties = {}
    if not props:
        return properties
    for p in props:
        properties[format_property_key(p.key)] = p.value
    return properties

def normalize_relation_name(relation):
    """è§„èŒƒåŒ–å…³ç³»åç§°ï¼Œå»é™¤ç‰¹æ®Šå­—ç¬¦å¹¶å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿"""
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    normalized = re.sub(r'[^\w\s]', '', relation)
    # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
    normalized = re.sub(r'\s+', '_', normalized)
    # ç¡®ä¿éç©º
    if not normalized:
        normalized = 'relates_to'
    return normalized

def chunk_text(text, max_chunk_size=8000, overlap=500):
    """å°†é•¿æ–‡æœ¬åˆ†æˆå¤šä¸ªå—ï¼Œå¸¦æœ‰é‡å ä»¥ä¿æŒä¸Šä¸‹æ–‡"""
    if len(text) <= max_chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = min(start + max_chunk_size, len(text))
        
        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå—ï¼Œå°è¯•åœ¨ä¸€ä¸ªè‡ªç„¶çš„æ–­ç‚¹å¤„åˆ†å‰²
        if end < len(text):
            # å°è¯•åœ¨æ®µè½ç»“æŸå¤„åˆ†å‰²
            paragraph_end = text.rfind('\n\n', start, end)
            if paragraph_end != -1 and paragraph_end > start + max_chunk_size // 2:
                end = paragraph_end + 2  # +2 to include the newlines
            else:
                # å°è¯•åœ¨å¥å­ç»“æŸå¤„åˆ†å‰²
                sentence_end = text.rfind('. ', start, end)
                if sentence_end != -1 and sentence_end > start + max_chunk_size // 2:
                    end = sentence_end + 2  # +2 to include the period and space
        
        chunks.append(text[start:end])
        
        # ç§»åŠ¨èµ·ç‚¹ï¼Œè€ƒè™‘é‡å 
        start = end - overlap if end < len(text) else len(text)
    
    return chunks

def normalize_node_type(node_type):
    """è§„èŒƒåŒ–èŠ‚ç‚¹ç±»å‹åç§°ï¼Œç¡®ä¿Neo4jå…¼å®¹"""
    # ç§»é™¤æˆ–æ›¿æ¢ç‰¹æ®Šå­—ç¬¦
    normalized = re.sub(r'[^\w\u4e00-\u9fff]', '_', node_type)  # ä¿ç•™ä¸­æ–‡å­—ç¬¦
    # ç¡®ä¿ä¸ä»¥æ•°å­—å¼€å¤´
    if normalized and normalized[0].isdigit():
        normalized = 'Type_' + normalized
    # ç¡®ä¿éç©º
    if not normalized:
        normalized = 'Unknown'
    return normalized

# ==================== JSON å¤„ç†å‡½æ•° ====================

def complete_truncated_json(json_str):
    """å°è¯•è¡¥å…¨è¢«æˆªæ–­çš„JSON"""
    print(f"ğŸ”§ å°è¯•è¡¥å…¨JSON: {json_str[-50:]}")
    
    # è®¡ç®—æ‹¬å·å¹³è¡¡
    open_braces = json_str.count('{') - json_str.count('}')
    open_brackets = json_str.count('[') - json_str.count(']')
    
    # è¡¥å…¨ç¼ºå¤±çš„æ‹¬å·
    completion = ''
    if open_brackets > 0:
        completion += ']' * open_brackets
    if open_braces > 0:
        completion += '}' * open_braces
    
    completed = json_str + completion
    print(f"ğŸ”§ è¡¥å…¨åçš„JSON: {completed}")
    return completed

def fix_json_format_advanced(json_str):
    """é«˜çº§JSONæ ¼å¼ä¿®å¤"""
    try:
        print("ğŸ”§ å¼€å§‹é«˜çº§JSONä¿®å¤...")
        
        # ç§»é™¤å¯èƒ½çš„å‰åç¼€
        json_str = re.sub(r'^.*?({.*}).*?$', r'\1', json_str, flags=re.DOTALL)
        
        # æ›¿æ¢å•å¼•å·ä¸ºåŒå¼•å·ï¼ˆæ›´ç²¾ç¡®çš„åŒ¹é…ï¼‰
        json_str = re.sub(r"'([^']*?)'(\s*:)", r'"\1"\2', json_str)  # é”®
        json_str = re.sub(r":\s*'([^']*?)'", r': "\1"', json_str)    # å€¼
        
        # ä¿®å¤Pythonå¸ƒå°”å€¼å’ŒNone
        json_str = re.sub(r'\bFalse\b', 'false', json_str)
        json_str = re.sub(r'\bTrue\b', 'true', json_str)
        json_str = re.sub(r'\bNone\b', 'null', json_str)
        
        # ä¿®å¤ç¼ºå¤±çš„é€—å·
        # åœ¨ } åé¢è·Ÿç€ { çš„æƒ…å†µ
        json_str = re.sub(r'}\s*(\n\s*){', '},\n{', json_str)
        # åœ¨ ] åé¢è·Ÿç€ { çš„æƒ…å†µ
        json_str = re.sub(r']\s*(\n\s*){', '],\n{', json_str)
        # åœ¨ } åé¢è·Ÿç€ [ çš„æƒ…å†µ
        json_str = re.sub(r'}\s*(\n\s*)\[', '},\n[', json_str)
        
        # ä¿®å¤å¯¹è±¡å†…ç¼ºå¤±çš„é€—å·
        json_str = re.sub(r'([}\]])\s*\n\s*"', r'\1,\n"', json_str)
        
        print(f"ğŸ”§ é«˜çº§ä¿®å¤åçš„JSON: {json_str}")
        return json_str
        
    except Exception as e:
        print(f"âŒ é«˜çº§JSONä¿®å¤å¤±è´¥: {e}")
        return None

def request_complete_json():
    """é‡æ–°è¯·æ±‚LLMç”Ÿæˆå®Œæ•´çš„JSON"""
    try:
        print("ğŸ¤– é‡æ–°è¯·æ±‚LLMç”Ÿæˆå®Œæ•´JSON...")
        
        fix_prompt = """
è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„çŸ¥è¯†å›¾è°±JSONï¼ŒåŒ…å«nodeså’Œrelsä¸¤ä¸ªå­—æ®µã€‚

è¦æ±‚ï¼š
1. å¿…é¡»æ˜¯å®Œæ•´çš„ã€æœ‰æ•ˆçš„JSONæ ¼å¼
2. åŒ…å«"nodes"æ•°ç»„å’Œ"rels"æ•°ç»„
3. å¦‚æœæ²¡æœ‰å…³ç³»ï¼Œrelså¯ä»¥æ˜¯ç©ºæ•°ç»„[]
4. æ¯ä¸ªèŠ‚ç‚¹å¿…é¡»æœ‰idã€typeã€propertieså­—æ®µ
5. ç¡®ä¿JSONå®Œæ•´ï¼Œä¸è¦è¢«æˆªæ–­

è¯·ç”Ÿæˆä¸€ä¸ªå…³äºå‘åŠ¨æœºçš„ç®€å•çŸ¥è¯†å›¾è°±ç¤ºä¾‹ï¼š

åªè¿”å›JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼š
"""
        
        fix_response, _ = llm_client.chat_completion(fix_prompt)
        
        # æ¸…ç†å“åº”
        fixed_json = fix_response.strip()
        if '```' in fixed_json:
            json_match = re.search(r'```(?:json)?(.*?)```', fixed_json, re.DOTALL)
            if json_match:
                fixed_json = json_match.group(1).strip()
        
        print(f"ğŸ¤– é‡æ–°ç”Ÿæˆçš„JSON: {fixed_json}")
        return json.loads(fixed_json)
        
    except Exception as e:
        print(f"âŒ é‡æ–°ç”ŸæˆJSONå¤±è´¥: {e}")
        return None

def extract_json_from_response(response):
    """ä»LLMå“åº”ä¸­æå–JSONéƒ¨åˆ†ï¼ˆå®Œå…¨é‡å†™ç‰ˆï¼‰"""
    print(f"ğŸ” åŸå§‹LLMå“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
    print(f"ğŸ” åŸå§‹LLMå“åº”: {response}")
    
    # å°è¯•å¯»æ‰¾JSONä»£ç å—
    json_match = re.search(r'```(?:json)?(.*?)```', response, re.DOTALL)
    if json_match:
        json_str = json_match.group(1).strip()
        print("ğŸ“„ æ‰¾åˆ°JSONä»£ç å—")
    else:
        # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
        json_str = response.strip()
        print("ğŸ“„ ä½¿ç”¨æ•´ä¸ªå“åº”ä½œä¸ºJSON")
    
    # å¦‚æœJSONå­—ç¬¦ä¸²è¢«æˆªæ–­ï¼Œå°è¯•è¡¥å…¨
    if not json_str.endswith('}') and not json_str.endswith(']'):
        print("âš ï¸ JSONå¯èƒ½è¢«æˆªæ–­ï¼Œå°è¯•è¡¥å…¨...")
        json_str = complete_truncated_json(json_str)
    
    # å°è¯•è§£æJSON
    try:
        print(f"ğŸ§¹ å‡†å¤‡è§£æçš„JSON: {json_str}")
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        print(f"ğŸ” é”™è¯¯ä½ç½®: {e.pos}, é”™è¯¯è¡Œåˆ—: line {e.lineno} column {e.colno}")
        
        # å°è¯•ä¿®å¤JSON
        fixed_json = fix_json_format_advanced(json_str)
        if fixed_json:
            try:
                print(f"ğŸ”§ å°è¯•è§£æä¿®å¤åçš„JSON: {fixed_json}")
                return json.loads(fixed_json)
            except json.JSONDecodeError as e2:
                print(f"âŒ ä¿®å¤åJSONä»ç„¶å¤±è´¥: {e2}")
        
        # æœ€åå°è¯•ï¼šé‡æ–°è¯·æ±‚LLMç”Ÿæˆå®Œæ•´JSON
        return request_complete_json()

# ==================== çŸ¥è¯†å›¾è°±æå–å‡½æ•° ====================

def extract_knowledge_graph_from_text(document_text):
    """ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    
    # ä½¿ç”¨æ›´æ˜ç¡®çš„æç¤ºï¼Œå¼ºè°ƒpropertiesæ ¼å¼
    prompt = f"""
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–çŸ¥è¯†å›¾è°±ï¼Œè¿”å›JSONæ ¼å¼ã€‚

æ–‡æœ¬ï¼š{document_text[:2000]}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šï¼š

{{
  "nodes": [
    {{
      "id": "å®ä½“åç§°", 
      "type": "å®ä½“ç±»å‹", 
      "properties": [
        {{"key": "å±æ€§å", "value": "å±æ€§å€¼"}}
      ]
    }}
  ],
  "rels": [
    {{
      "source": {{"id": "æºå®ä½“", "type": "æºç±»å‹", "properties": []}}, 
      "target": {{"id": "ç›®æ ‡å®ä½“", "type": "ç›®æ ‡ç±»å‹", "properties": []}}, 
      "type": "å…³ç³»ç±»å‹",
      "properties": []
    }}
  ]
}}

é‡è¦æ ¼å¼è¦æ±‚ï¼š
1. å®ä½“ç±»å‹åªèƒ½æ˜¯ï¼šè®¾å¤‡ã€éƒ¨ä»¶ã€æŠ€æœ¯ã€ææ–™ã€è¿‡ç¨‹ã€å‚æ•°ã€ç»„ç»‡ã€åœ°ç‚¹
2. properties å¿…é¡»æ˜¯å¯¹è±¡æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "key" å’Œ "value" å­—æ®µ
3. å¦‚æœæ²¡æœ‰å±æ€§ï¼Œproperties è®¾ä¸ºç©ºæ•°ç»„ []
4. å¦‚æœæ²¡æœ‰å…³ç³»ï¼Œrels è®¾ä¸ºç©ºæ•°ç»„ []

åªè¿”å›æœ‰æ•ˆçš„JSONï¼Œç¡®ä¿å®Œæ•´ï¼š
"""
    
    # è°ƒç”¨LLM
    try:
        print("ğŸ¤– è°ƒç”¨LLMæå–çŸ¥è¯†å›¾è°±...")
        response, _ = llm_client.chat_completion(prompt)
        
        # è§£æå“åº”ä¸­çš„JSON
        kg_data = extract_json_from_response(response)
        if not kg_data:
            print("âŒ æ— æ³•ä»LLMå“åº”ä¸­æå–æœ‰æ•ˆçš„JSONï¼Œå°è¯•é™çº§ç­–ç•¥")
            return extract_simple_entities(document_text)
        
        # âœ… ä½¿ç”¨æ”¹è¿›çš„éªŒè¯å‡½æ•°
        if not validate_kg_structure(kg_data):
            print("âŒ JSONç»“æ„éªŒè¯å¤±è´¥ï¼Œå°è¯•é™çº§ç­–ç•¥")
            return extract_simple_entities(document_text)
            
        # è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®
        try:
            knowledge_graph = KnowledgeGraph.parse_obj(kg_data)
            print(f"âœ… æˆåŠŸæå–çŸ¥è¯†å›¾è°±: {len(knowledge_graph.nodes)}ä¸ªèŠ‚ç‚¹, {len(knowledge_graph.rels)}ä¸ªå…³ç³»")
            return knowledge_graph
        except Exception as e:
            print(f"âŒ PydanticéªŒè¯å¤±è´¥: {e}")
            print("ğŸ”§ å°è¯•å†æ¬¡ä¿®å¤æ•°æ®æ ¼å¼...")
            # å†æ¬¡å°è¯•ä¿®å¤
            if validate_kg_structure(kg_data):
                try:
                    knowledge_graph = KnowledgeGraph.parse_obj(kg_data)
                    print(f"âœ… ä¿®å¤åæˆåŠŸåˆ›å»ºçŸ¥è¯†å›¾è°±: {len(knowledge_graph.nodes)}ä¸ªèŠ‚ç‚¹")
                    return knowledge_graph
                except Exception as e2:
                    print(f"âŒ ä¿®å¤åä»ç„¶å¤±è´¥: {e2}")
            return extract_simple_entities(document_text)
            
    except Exception as e:
        print(f"âŒ çŸ¥è¯†å›¾è°±æå–å¤±è´¥: {e}")
        return extract_simple_entities(document_text)

def validate_kg_structure(kg_data):
    """éªŒè¯çŸ¥è¯†å›¾è°±æ•°æ®ç»“æ„"""
    if not isinstance(kg_data, dict):
        print("âŒ ä¸æ˜¯å­—å…¸ç±»å‹")
        return False
        
    if 'nodes' not in kg_data:
        print("âŒ ç¼ºå°‘nodeså­—æ®µ")
        return False
        
    if 'rels' not in kg_data:
        print("âš ï¸ ç¼ºå°‘relså­—æ®µï¼Œæ·»åŠ ç©ºæ•°ç»„")
        kg_data['rels'] = []
    
    if not isinstance(kg_data['nodes'], list):
        print("âŒ nodesä¸æ˜¯æ•°ç»„")
        return False
        
    if not isinstance(kg_data['rels'], list):
        print("âŒ relsä¸æ˜¯æ•°ç»„")
        kg_data['rels'] = []
    
    # éªŒè¯å’Œä¿®å¤èŠ‚ç‚¹ç»“æ„
    for i, node in enumerate(kg_data['nodes']):
        if not isinstance(node, dict):
            print(f"âŒ èŠ‚ç‚¹{i}ä¸æ˜¯å­—å…¸")
            return False
        if 'id' not in node:
            print(f"âŒ èŠ‚ç‚¹{i}ç¼ºå°‘idå­—æ®µ")
            return False
        if 'type' not in node:
            print(f"âš ï¸ èŠ‚ç‚¹{i}ç¼ºå°‘typeå­—æ®µï¼Œè®¾ä¸ºé»˜è®¤å€¼")
            node['type'] = 'å®ä½“'
        
        # âœ… ä¿®å¤ properties å­—æ®µæ ¼å¼
        if 'properties' not in node:
            node['properties'] = []
        else:
            # å¦‚æœ properties æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œè½¬æ¢ä¸º Property å¯¹è±¡åˆ—è¡¨
            if isinstance(node['properties'], list):
                fixed_properties = []
                for j, prop in enumerate(node['properties']):
                    if isinstance(prop, str):
                        # å­—ç¬¦ä¸²è½¬æ¢ä¸º Property å¯¹è±¡æ ¼å¼
                        fixed_properties.append({
                            "key": f"description_{j}",
                            "value": prop
                        })
                        print(f"ğŸ”§ ä¿®å¤èŠ‚ç‚¹{i}çš„å±æ€§{j}: '{prop}' -> {{key: 'description_{j}', value: '{prop}'}}")
                    elif isinstance(prop, dict) and 'key' in prop and 'value' in prop:
                        # å·²ç»æ˜¯æ­£ç¡®æ ¼å¼
                        fixed_properties.append(prop)
                    else:
                        # å…¶ä»–æ ¼å¼ï¼Œå°è¯•è½¬æ¢
                        try:
                            fixed_properties.append({
                                "key": "property",
                                "value": str(prop)
                            })
                            print(f"ğŸ”§ ä¿®å¤èŠ‚ç‚¹{i}çš„å±æ€§{j}: {prop} -> {{key: 'property', value: '{str(prop)}'}}")
                        except:
                            print(f"âš ï¸ è·³è¿‡èŠ‚ç‚¹{i}çš„æ— æ•ˆå±æ€§{j}: {prop}")
                
                node['properties'] = fixed_properties
            else:
                # properties ä¸æ˜¯åˆ—è¡¨ï¼Œé‡ç½®ä¸ºç©ºåˆ—è¡¨
                print(f"âš ï¸ èŠ‚ç‚¹{i}çš„propertiesä¸æ˜¯åˆ—è¡¨ï¼Œé‡ç½®ä¸ºç©º")
                node['properties'] = []
    
    # éªŒè¯å…³ç³»ç»“æ„
    valid_rels = []
    for i, rel in enumerate(kg_data['rels']):
        if not isinstance(rel, dict):
            print(f"âš ï¸ å…³ç³»{i}ä¸æ˜¯å­—å…¸ï¼Œè·³è¿‡")
            continue
            
        if not all(key in rel for key in ['source', 'target', 'type']):
            print(f"âš ï¸ å…³ç³»{i}ç¼ºå°‘å¿…éœ€å­—æ®µï¼Œè·³è¿‡")
            continue
            
        # éªŒè¯å¹¶ä¿®å¤sourceå’Œtarget
        for field in ['source', 'target']:
            if not isinstance(rel[field], dict) or 'id' not in rel[field]:
                print(f"âš ï¸ å…³ç³»{i}çš„{field}æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                break
            if 'type' not in rel[field]:
                rel[field]['type'] = 'å®ä½“'
            # ç¡®ä¿sourceå’Œtargetä¹Ÿæœ‰æ­£ç¡®çš„propertiesæ ¼å¼
            if 'properties' not in rel[field]:
                rel[field]['properties'] = []
        else:
            # ä¿®å¤å…³ç³»çš„properties
            if 'properties' not in rel:
                rel['properties'] = []
            elif isinstance(rel['properties'], list):
                fixed_rel_properties = []
                for j, prop in enumerate(rel['properties']):
                    if isinstance(prop, str):
                        fixed_rel_properties.append({
                            "key": f"description_{j}",
                            "value": prop
                        })
                    elif isinstance(prop, dict) and 'key' in prop and 'value' in prop:
                        fixed_rel_properties.append(prop)
                    else:
                        try:
                            fixed_rel_properties.append({
                                "key": "property",
                                "value": str(prop)
                            })
                        except:
                            continue
                rel['properties'] = fixed_rel_properties
            else:
                rel['properties'] = []
            
            valid_rels.append(rel)
    
    kg_data['rels'] = valid_rels
    return True

# åŒæ—¶ä¼˜åŒ– extract_simple_entities å‡½æ•°çš„æç¤ºï¼Œé¿å…ç”Ÿæˆé”™è¯¯æ ¼å¼ï¼š

def extract_simple_entities(document_text):
    """ç®€å•çš„å®ä½“æå–ä½œä¸ºé™çº§ç­–ç•¥"""
    print("ğŸ”„ ä½¿ç”¨é™çº§ç­–ç•¥ï¼šç®€å•å®ä½“æå–")
    
    prompt = f"""
ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–é‡è¦å®ä½“ï¼Œè¿”å›ç®€å•çš„JSONï¼š

æ–‡æœ¬ï¼š{document_text[:1000]}

è¿”å›æ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰ç…§æ­¤æ ¼å¼ï¼‰ï¼š
{{
  "nodes": [
    {{"id": "æ´»å¡å¼å‘åŠ¨æœº", "type": "è®¾å¤‡", "properties": []}},
    {{"id": "æ°”ç¼¸", "type": "éƒ¨ä»¶", "properties": []}},
    {{"id": "æ´»å¡", "type": "éƒ¨ä»¶", "properties": []}}
  ],
  "rels": []
}}

é‡è¦è¯´æ˜ï¼š
1. properties å¿…é¡»æ˜¯ç©ºæ•°ç»„ []ï¼Œä¸è¦æ·»åŠ ä»»ä½•å†…å®¹
2. åªæå–å®ä½“ï¼Œä¸æå–å…³ç³»
3. å®ä½“ç±»å‹åªèƒ½æ˜¯ï¼šè®¾å¤‡ã€éƒ¨ä»¶ã€æŠ€æœ¯ã€ææ–™
4. ç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®

åªè¿”å›JSONï¼Œä¸è¦ä»»ä½•è§£é‡Šï¼š
"""
    
    try:
        response, _ = llm_client.chat_completion(prompt)
        
        # ç®€å•çš„JSONæå–
        json_str = response.strip()
        if '```' in json_str:
            json_match = re.search(r'```(?:json)?(.*?)```', json_str, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
        
        # ç¡®ä¿JSONå®Œæ•´
        if not json_str.endswith('}'):
            json_str = complete_truncated_json(json_str)
        
        kg_data = json.loads(json_str)
        
        # ç¡®ä¿æœ‰relså­—æ®µ
        if 'rels' not in kg_data:
            kg_data['rels'] = []
            
        # âœ… åº”ç”¨æ–°çš„éªŒè¯å’Œä¿®å¤é€»è¾‘
        if validate_kg_structure(kg_data):
            return KnowledgeGraph.parse_obj(kg_data)
            
    except Exception as e:
        print(f"âŒ ç®€å•å®ä½“æå–ä¹Ÿå¤±è´¥: {e}")
    
    # æœ€åçš„é™çº§ç­–ç•¥ï¼šåˆ›å»ºåŸºæœ¬çš„å›¾è°±
    return create_basic_kg(document_text)

# åŒæ—¶ä¼˜åŒ–ä¸»è¦çš„æå–å‡½æ•°ï¼Œæ”¹è¿›æç¤ºæ ¼å¼ï¼š

def extract_knowledge_graph_from_text(document_text):
    """ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    
    # ä½¿ç”¨æ›´æ˜ç¡®çš„æç¤ºï¼Œå¼ºè°ƒpropertiesæ ¼å¼
    prompt = f"""
è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–çŸ¥è¯†å›¾è°±ï¼Œè¿”å›JSONæ ¼å¼ã€‚

æ–‡æœ¬ï¼š{document_text[:2000]}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šï¼š

{{
  "nodes": [
    {{
      "id": "å®ä½“åç§°", 
      "type": "å®ä½“ç±»å‹", 
      "properties": [
        {{"key": "å±æ€§å", "value": "å±æ€§å€¼"}}
      ]
    }}
  ],
  "rels": [
    {{
      "source": {{"id": "æºå®ä½“", "type": "æºç±»å‹", "properties": []}}, 
      "target": {{"id": "ç›®æ ‡å®ä½“", "type": "ç›®æ ‡ç±»å‹", "properties": []}}, 
      "type": "å…³ç³»ç±»å‹",
      "properties": []
    }}
  ]
}}

é‡è¦æ ¼å¼è¦æ±‚ï¼š
1. å®ä½“ç±»å‹åªèƒ½æ˜¯ï¼šè®¾å¤‡ã€éƒ¨ä»¶ã€æŠ€æœ¯ã€ææ–™ã€è¿‡ç¨‹ã€å‚æ•°ã€ç»„ç»‡ã€åœ°ç‚¹
2. properties å¿…é¡»æ˜¯å¯¹è±¡æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« "key" å’Œ "value" å­—æ®µ
3. å¦‚æœæ²¡æœ‰å±æ€§ï¼Œproperties è®¾ä¸ºç©ºæ•°ç»„ []
4. å¦‚æœæ²¡æœ‰å…³ç³»ï¼Œrels è®¾ä¸ºç©ºæ•°ç»„ []

åªè¿”å›æœ‰æ•ˆçš„JSONï¼Œç¡®ä¿å®Œæ•´ï¼š
"""
    
    # è°ƒç”¨LLM
    try:
        print("ğŸ¤– è°ƒç”¨LLMæå–çŸ¥è¯†å›¾è°±...")
        response, _ = llm_client.chat_completion(prompt)
        
        # è§£æå“åº”ä¸­çš„JSON
        kg_data = extract_json_from_response(response)
        if not kg_data:
            print("âŒ æ— æ³•ä»LLMå“åº”ä¸­æå–æœ‰æ•ˆçš„JSONï¼Œå°è¯•é™çº§ç­–ç•¥")
            return extract_simple_entities(document_text)
        
        # âœ… ä½¿ç”¨æ”¹è¿›çš„éªŒè¯å‡½æ•°
        if not validate_kg_structure(kg_data):
            print("âŒ JSONç»“æ„éªŒè¯å¤±è´¥ï¼Œå°è¯•é™çº§ç­–ç•¥")
            return extract_simple_entities(document_text)
            
        # è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®
        try:
            knowledge_graph = KnowledgeGraph.parse_obj(kg_data)
            print(f"âœ… æˆåŠŸæå–çŸ¥è¯†å›¾è°±: {len(knowledge_graph.nodes)}ä¸ªèŠ‚ç‚¹, {len(knowledge_graph.rels)}ä¸ªå…³ç³»")
            return knowledge_graph
        except Exception as e:
            print(f"âŒ PydanticéªŒè¯å¤±è´¥: {e}")
            print("ğŸ”§ å°è¯•å†æ¬¡ä¿®å¤æ•°æ®æ ¼å¼...")
            # å†æ¬¡å°è¯•ä¿®å¤
            if validate_kg_structure(kg_data):
                try:
                    knowledge_graph = KnowledgeGraph.parse_obj(kg_data)
                    print(f"âœ… ä¿®å¤åæˆåŠŸåˆ›å»ºçŸ¥è¯†å›¾è°±: {len(knowledge_graph.nodes)}ä¸ªèŠ‚ç‚¹")
                    return knowledge_graph
                except Exception as e2:
                    print(f"âŒ ä¿®å¤åä»ç„¶å¤±è´¥: {e2}")
            return extract_simple_entities(document_text)
            
    except Exception as e:
        print(f"âŒ çŸ¥è¯†å›¾è°±æå–å¤±è´¥: {e}")
        return extract_simple_entities(document_text)

def validate_kg_structure(kg_data):
    """éªŒè¯çŸ¥è¯†å›¾è°±æ•°æ®ç»“æ„"""
    if not isinstance(kg_data, dict):
        print("âŒ ä¸æ˜¯å­—å…¸ç±»å‹")
        return False
        
    if 'nodes' not in kg_data:
        print("âŒ ç¼ºå°‘nodeså­—æ®µ")
        return False
        
    if 'rels' not in kg_data:
        print("âš ï¸ ç¼ºå°‘relså­—æ®µï¼Œæ·»åŠ ç©ºæ•°ç»„")
        kg_data['rels'] = []
    
    if not isinstance(kg_data['nodes'], list):
        print("âŒ nodesä¸æ˜¯æ•°ç»„")
        return False
        
    if not isinstance(kg_data['rels'], list):
        print("âŒ relsä¸æ˜¯æ•°ç»„")
        kg_data['rels'] = []
    
    # éªŒè¯å’Œä¿®å¤èŠ‚ç‚¹ç»“æ„
    for i, node in enumerate(kg_data['nodes']):
        if not isinstance(node, dict):
            print(f"âŒ èŠ‚ç‚¹{i}ä¸æ˜¯å­—å…¸")
            return False
        if 'id' not in node:
            print(f"âŒ èŠ‚ç‚¹{i}ç¼ºå°‘idå­—æ®µ")
            return False
        if 'type' not in node:
            print(f"âš ï¸ èŠ‚ç‚¹{i}ç¼ºå°‘typeå­—æ®µï¼Œè®¾ä¸ºé»˜è®¤å€¼")
            node['type'] = 'å®ä½“'
        
        # âœ… ä¿®å¤ properties å­—æ®µæ ¼å¼
        if 'properties' not in node:
            node['properties'] = []
        else:
            # å¦‚æœ properties æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œè½¬æ¢ä¸º Property å¯¹è±¡åˆ—è¡¨
            if isinstance(node['properties'], list):
                fixed_properties = []
                for j, prop in enumerate(node['properties']):
                    if isinstance(prop, str):
                        # å­—ç¬¦ä¸²è½¬æ¢ä¸º Property å¯¹è±¡æ ¼å¼
                        fixed_properties.append({
                            "key": f"description_{j}",
                            "value": prop
                        })
                        print(f"ğŸ”§ ä¿®å¤èŠ‚ç‚¹{i}çš„å±æ€§{j}: '{prop}' -> {{key: 'description_{j}', value: '{prop}'}}")
                    elif isinstance(prop, dict) and 'key' in prop and 'value' in prop:
                        # å·²ç»æ˜¯æ­£ç¡®æ ¼å¼
                        fixed_properties.append(prop)
                    else:
                        # å…¶ä»–æ ¼å¼ï¼Œå°è¯•è½¬æ¢
                        try:
                            fixed_properties.append({
                                "key": "property",
                                "value": str(prop)
                            })
                            print(f"ğŸ”§ ä¿®å¤èŠ‚ç‚¹{i}çš„å±æ€§{j}: {prop} -> {{key: 'property', value: '{str(prop)}'}}")
                        except:
                            print(f"âš ï¸ è·³è¿‡èŠ‚ç‚¹{i}çš„æ— æ•ˆå±æ€§{j}: {prop}")
                
                node['properties'] = fixed_properties
            else:
                # properties ä¸æ˜¯åˆ—è¡¨ï¼Œé‡ç½®ä¸ºç©ºåˆ—è¡¨
                print(f"âš ï¸ èŠ‚ç‚¹{i}çš„propertiesä¸æ˜¯åˆ—è¡¨ï¼Œé‡ç½®ä¸ºç©º")
                node['properties'] = []
    
    # éªŒè¯å…³ç³»ç»“æ„
    valid_rels = []
    for i, rel in enumerate(kg_data['rels']):
        if not isinstance(rel, dict):
            print(f"âš ï¸ å…³ç³»{i}ä¸æ˜¯å­—å…¸ï¼Œè·³è¿‡")
            continue
            
        if not all(key in rel for key in ['source', 'target', 'type']):
            print(f"âš ï¸ å…³ç³»{i}ç¼ºå°‘å¿…éœ€å­—æ®µï¼Œè·³è¿‡")
            continue
            
        # éªŒè¯å¹¶ä¿®å¤sourceå’Œtarget
        for field in ['source', 'target']:
            if not isinstance(rel[field], dict) or 'id' not in rel[field]:
                print(f"âš ï¸ å…³ç³»{i}çš„{field}æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                break
            if 'type' not in rel[field]:
                rel[field]['type'] = 'å®ä½“'
            # ç¡®ä¿sourceå’Œtargetä¹Ÿæœ‰æ­£ç¡®çš„propertiesæ ¼å¼
            if 'properties' not in rel[field]:
                rel[field]['properties'] = []
        else:
            # ä¿®å¤å…³ç³»çš„properties
            if 'properties' not in rel:
                rel['properties'] = []
            elif isinstance(rel['properties'], list):
                fixed_rel_properties = []
                for j, prop in enumerate(rel['properties']):
                    if isinstance(prop, str):
                        fixed_rel_properties.append({
                            "key": f"description_{j}",
                            "value": prop
                        })
                    elif isinstance(prop, dict) and 'key' in prop and 'value' in prop:
                        fixed_rel_properties.append(prop)
                    else:
                        try:
                            fixed_rel_properties.append({
                                "key": "property",
                                "value": str(prop)
                            })
                        except:
                            continue
                rel['properties'] = fixed_rel_properties
            else:
                rel['properties'] = []
            
            valid_rels.append(rel)
    
    kg_data['rels'] = valid_rels
    return True

def create_basic_kg(document_text):
    """åˆ›å»ºåŸºæœ¬çš„çŸ¥è¯†å›¾è°±ä½œä¸ºæœ€åçš„é™çº§ç­–ç•¥"""
    print("ğŸ”„ ä½¿ç”¨æœ€åé™çº§ç­–ç•¥ï¼šåˆ›å»ºåŸºæœ¬å›¾è°±")
    
    # ä½¿ç”¨ç®€å•çš„å…³é”®è¯æå–
    keywords = ["å‘åŠ¨æœº", "æ°”ç¼¸", "æ´»å¡", "è¿æ†", "æ›²è½´", "æ°”é—¨", "èºæ—‹æ¡¨", "å‡é€Ÿå™¨", "æœºåŒ£", 
                "ç‡ƒçƒ§", "æ··åˆæ°”", "å‹ç¼©", "æ’æ°”", "è¿›æ°”", "å†·å´", "æ¶¦æ»‘", "ç‚¹ç«", "å¯åŠ¨",
                "è®¾å¤‡", "éƒ¨ä»¶", "ç³»ç»Ÿ", "ç»„ä»¶", "æœºæ„", "è£…ç½®", "ææ–™", "æŠ€æœ¯"]
    
    nodes = []
    found_keywords = []
    
    # åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾å…³é”®è¯
    for keyword in keywords:
        if keyword in document_text:
            found_keywords.append(keyword)
    
    # å¦‚æœæ‰¾åˆ°å…³é”®è¯ï¼Œä¸ºæ¯ä¸ªåˆ›å»ºèŠ‚ç‚¹
    if found_keywords:
        for i, keyword in enumerate(found_keywords[:10]):  # æœ€å¤š10ä¸ªèŠ‚ç‚¹
            # æ ¹æ®å…³é”®è¯ç±»å‹ç¡®å®šèŠ‚ç‚¹ç±»å‹
            if keyword in ["å‘åŠ¨æœº", "å‡é€Ÿå™¨", "èºæ—‹æ¡¨"]:
                node_type = "è®¾å¤‡"
            elif keyword in ["æ°”ç¼¸", "æ´»å¡", "è¿æ†", "æ›²è½´", "æ°”é—¨", "æœºåŒ£"]:
                node_type = "éƒ¨ä»¶"
            elif keyword in ["ç‡ƒçƒ§", "å‹ç¼©", "æ’æ°”", "è¿›æ°”", "å†·å´", "æ¶¦æ»‘", "ç‚¹ç«", "å¯åŠ¨"]:
                node_type = "è¿‡ç¨‹"
            elif keyword in ["æ··åˆæ°”", "ææ–™"]:
                node_type = "ææ–™"
            elif keyword in ["æŠ€æœ¯"]:
                node_type = "æŠ€æœ¯"
            else:
                node_type = "å®ä½“"
            
            # åˆ›å»ºèŠ‚ç‚¹ï¼Œpropertiesä¸ºç©ºæ•°ç»„ä»¥é¿å…Pydanticé”™è¯¯
            node = Node(
                id=keyword, 
                type=node_type, 
                properties=[]  # ç©ºçš„Propertyå¯¹è±¡åˆ—è¡¨
            )
            nodes.append(node)
            print(f"ğŸ“ åˆ›å»ºåŸºæœ¬èŠ‚ç‚¹: {keyword} ({node_type})")
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å…³é”®è¯ï¼Œåˆ›å»ºä¸€ä¸ªé€šç”¨èŠ‚ç‚¹
    if not nodes:
        print("âš ï¸ æœªæ‰¾åˆ°å…³é”®è¯ï¼Œåˆ›å»ºé€šç”¨æ–‡æ¡£å®ä½“")
        # å°è¯•ä»æ–‡æ¡£å¼€å¤´æå–ä¸€äº›æ–‡å­—ä½œä¸ºå®ä½“åç§°
        doc_words = document_text.split()[:3]  # å–å‰3ä¸ªè¯
        entity_name = "".join(doc_words) if doc_words else "æ–‡æ¡£å®ä½“"
        
        node = Node(
            id=entity_name, 
            type="å®ä½“", 
            properties=[]
        )
        nodes.append(node)
    
    print(f"âœ… åˆ›å»ºåŸºæœ¬çŸ¥è¯†å›¾è°±: {len(nodes)}ä¸ªèŠ‚ç‚¹")
    
    # è¿”å›åªæœ‰èŠ‚ç‚¹æ²¡æœ‰å…³ç³»çš„çŸ¥è¯†å›¾è°±
    return KnowledgeGraph(nodes=nodes, rels=[])

def extract_entities_by_pattern(document_text):
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼æå–å®ä½“"""
    entities = []
    
    # ä¸­æ–‡å®ä½“æ¨¡å¼
    chinese_patterns = [
        r'[ä¸€-é¾Ÿ]{2,6}å‘åŠ¨æœº',  # XXå‘åŠ¨æœº
        r'[ä¸€-é¾Ÿ]{1,3}æ°”ç¼¸',    # Xæ°”ç¼¸
        r'[ä¸€-é¾Ÿ]{2,4}ç³»ç»Ÿ',    # XXç³»ç»Ÿ
        r'[ä¸€-é¾Ÿ]{2,4}è£…ç½®',    # XXè£…ç½®
        r'[ä¸€-é¾Ÿ]{1,3}å‹',      # Xå‹
    ]
    
    # è‹±æ–‡å®ä½“æ¨¡å¼
    english_patterns = [
        r'[A-Z][a-z]+ Engine',
        r'[A-Z][a-z]+ System',
        r'[A-Z]{2,5}-\d+',  # å‹å·æ¨¡å¼ï¼Œå¦‚ CFM-56
    ]
    
    all_patterns = chinese_patterns + english_patterns
    
    for pattern in all_patterns:
        matches = re.findall(pattern, document_text)
        for match in matches:
            if match not in entities and len(match) > 1:
                entities.append(match)
    
    return entities[:8]  # æœ€å¤šè¿”å›8ä¸ªå®ä½“

def create_enhanced_basic_kg(document_text):
    """åˆ›å»ºå¢å¼ºç‰ˆæœ¬çš„åŸºæœ¬çŸ¥è¯†å›¾è°±"""
    print("ğŸ”„ ä½¿ç”¨å¢å¼ºç‰ˆåŸºæœ¬å›¾è°±åˆ›å»º")
    
    # ä½¿ç”¨æ¨¡å¼æå–
    pattern_entities = extract_entities_by_pattern(document_text)
    
    # ä½¿ç”¨å…³é”®è¯æå–
    keyword_entities = []
    keywords = ["å‘åŠ¨æœº", "æ°”ç¼¸", "æ´»å¡", "è¿æ†", "æ›²è½´", "æ°”é—¨", "èºæ—‹æ¡¨", "å‡é€Ÿå™¨"]
    for keyword in keywords:
        if keyword in document_text:
            keyword_entities.append(keyword)
    
    # åˆå¹¶å®ä½“
    all_entities = list(set(pattern_entities + keyword_entities))
    
    if not all_entities:
        # å¦‚æœä»€ä¹ˆéƒ½æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨åŸå§‹çš„create_basic_kg
        return create_basic_kg(document_text)
    
    nodes = []
    for entity in all_entities[:10]:  # æœ€å¤š10ä¸ªèŠ‚ç‚¹
        # æ™ºèƒ½åˆ¤æ–­å®ä½“ç±»å‹
        if any(word in entity for word in ["å‘åŠ¨æœº", "Engine"]):
            node_type = "è®¾å¤‡"
        elif any(word in entity for word in ["æ°”ç¼¸", "æ´»å¡", "è¿æ†", "æ›²è½´", "æ°”é—¨"]):
            node_type = "éƒ¨ä»¶"
        elif any(word in entity for word in ["ç³»ç»Ÿ", "System"]):
            node_type = "ç³»ç»Ÿ"
        elif any(word in entity for word in ["è£…ç½®", "Device"]):
            node_type = "è£…ç½®"
        else:
            node_type = "å®ä½“"
        
        node = Node(
            id=entity,
            type=node_type,
            properties=[]
        )
        nodes.append(node)
        print(f"ğŸ“ åˆ›å»ºå¢å¼ºèŠ‚ç‚¹: {entity} ({node_type})")
    
    print(f"âœ… åˆ›å»ºå¢å¼ºåŸºæœ¬çŸ¥è¯†å›¾è°±: {len(nodes)}ä¸ªèŠ‚ç‚¹")
    return KnowledgeGraph(nodes=nodes, rels=[])

def merge_knowledge_graphs(knowledge_graphs):
    """åˆå¹¶å¤šä¸ªçŸ¥è¯†å›¾è°±ï¼Œå»é™¤é‡å¤çš„èŠ‚ç‚¹å’Œå…³ç³»"""
    if not knowledge_graphs:
        return KnowledgeGraph(nodes=[], rels=[])
    
    merged_nodes = {}
    merged_rels = []
    
    # åˆå¹¶èŠ‚ç‚¹ï¼Œä½¿ç”¨(id, type)ä½œä¸ºå”¯ä¸€é”®
    for kg in knowledge_graphs:
        if not kg or not kg.nodes:
            continue
            
        for node in kg.nodes:
            node_key = (node.id, node.type)
            if node_key not in merged_nodes:
                merged_nodes[node_key] = node
                print(f"ğŸ”„ åˆå¹¶èŠ‚ç‚¹: {node.id} ({node.type})")
    
    # åˆå¹¶å…³ç³»ï¼Œé¿å…é‡å¤
    rel_keys = set()
    for kg in knowledge_graphs:
        if not kg or not kg.rels:
            continue
            
        for rel in kg.rels:
            rel_key = (rel.source.id, rel.type, rel.target.id)
            if rel_key not in rel_keys:
                rel_keys.add(rel_key)
                # ç¡®ä¿ä½¿ç”¨åˆå¹¶åçš„èŠ‚ç‚¹
                source_key = (rel.source.id, rel.source.type)
                target_key = (rel.target.id, rel.target.type)
                if source_key in merged_nodes and target_key in merged_nodes:
                    merged_rels.append(rel)
                    print(f"ğŸ”— åˆå¹¶å…³ç³»: {rel.source.id} --{rel.type}--> {rel.target.id}")
    
    merged_kg = KnowledgeGraph(
        nodes=list(merged_nodes.values()),
        rels=merged_rels
    )
    
    print(f"âœ… çŸ¥è¯†å›¾è°±åˆå¹¶å®Œæˆ: {len(merged_kg.nodes)}ä¸ªèŠ‚ç‚¹, {len(merged_kg.rels)}ä¸ªå…³ç³»")
    return merged_kg

# ==================== Neo4j æ“ä½œå‡½æ•° ====================

def import_kg_to_neo4j(kg: KnowledgeGraph, graph_name: str = None, kg_id: str = None):
    """å°†çŸ¥è¯†å›¾è°±å¯¼å…¥åˆ°Neo4jæ•°æ®åº“ï¼ˆå­å›¾æ¨¡å¼ï¼‰"""
    try:
        print(f"ğŸš€ å¼€å§‹å¯¼å…¥çŸ¥è¯†å›¾è°±åˆ°Neo4j...")
        
        # è¿æ¥åˆ°Neo4j
        graph = Graph("bolt://localhost:7687", auth=("neo4j", "3080neo4j"), secure=False)
        
        # ç”Ÿæˆå­å›¾æ ‡ç­¾
        if kg_id:
            safe_kg_id = kg_id.replace('-', '_')
            subgraph_label = f"UserKG_{safe_kg_id}"
        else:
            subgraph_label = "UserKG_default"
        
        print(f"ğŸ“ ä½¿ç”¨å­å›¾æ ‡ç­¾: {subgraph_label}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'node_count': 0,
            'relation_count': 0,
            'entity_types': set(),
            'subgraph': subgraph_label
        }
        
        # å¯¼å…¥èŠ‚ç‚¹
        print("ğŸ“ å¯¼å…¥èŠ‚ç‚¹...")
        for node in kg.nodes:
            try:
                # è§„èŒƒåŒ–èŠ‚ç‚¹ç±»å‹
                node_type = normalize_node_type(node.type)
                stats['entity_types'].add(node_type)
                
                # å°†å±æ€§è½¬æ¢ä¸ºå­—å…¸
                node_props = props_to_dict(node.properties) if node.properties else {}
                
                # æ·»åŠ å…ƒæ•°æ®
                node_props['name'] = node.id
                node_props['node_type'] = node_type
                node_props['kg_id'] = kg_id or 'default'
                node_props['created_at'] = datetime.now().isoformat()
                
                # åˆ›å»ºCypheræŸ¥è¯¢ - ä½¿ç”¨å­å›¾æ ‡ç­¾å’ŒåŸå§‹ç±»å‹æ ‡ç­¾
                cypher = f"""
                MERGE (n:{subgraph_label}:{node_type} {{name: $name, kg_id: $kg_id}})
                SET n += $props
                RETURN n
                """
                
                result = graph.run(cypher, name=node.id, kg_id=kg_id, props=node_props)
                stats['node_count'] += 1
                
                print(f"âœ… å¯¼å…¥èŠ‚ç‚¹: {node.id} ({node_type})")
                
            except Exception as e:
                print(f"âŒ å¯¼å…¥èŠ‚ç‚¹å¤±è´¥ {node.id}: {e}")
                continue
        
        # å¯¼å…¥å…³ç³»
        print("ğŸ”— å¯¼å…¥å…³ç³»...")
        for rel in kg.rels:
            try:
                # è§„èŒƒåŒ–å…³ç³»ç±»å‹
                rel_type = normalize_relation_name(rel.type)
                
                # å°†å…³ç³»å±æ€§è½¬æ¢ä¸ºå­—å…¸
                rel_props = props_to_dict(rel.properties) if rel.properties else {}
                rel_props['kg_id'] = kg_id or 'default'
                rel_props['created_at'] = datetime.now().isoformat()
                
                # åˆ›å»ºå…³ç³»çš„CypheræŸ¥è¯¢
                cypher = f"""
                MATCH (s:{subgraph_label} {{name: $source_name, kg_id: $kg_id}})
                MATCH (t:{subgraph_label} {{name: $target_name, kg_id: $kg_id}})
                MERGE (s)-[r:{rel_type}]->(t)
                SET r += $props
                RETURN r
                """
                
                result = graph.run(cypher, 
                                 source_name=rel.source.id,
                                 target_name=rel.target.id,
                                 kg_id=kg_id,
                                 props=rel_props)
                
                stats['relation_count'] += 1
                print(f"âœ… å¯¼å…¥å…³ç³»: {rel.source.id} --{rel_type}--> {rel.target.id}")
                
            except Exception as e:
                print(f"âŒ å¯¼å…¥å…³ç³»å¤±è´¥: {e}")
                continue
        
        # è½¬æ¢é›†åˆä¸ºåˆ—è¡¨
        stats['entity_types'] = list(stats['entity_types'])
        
        print(f"âœ… çŸ¥è¯†å›¾è°±å¯¼å…¥å®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡: {stats['node_count']}ä¸ªèŠ‚ç‚¹, {stats['relation_count']}ä¸ªå…³ç³»")
        print(f"ğŸ·ï¸ å®ä½“ç±»å‹: {stats['entity_types']}")
        
        return stats
        
    except Exception as e:
        print(f"âŒ å¯¼å…¥Neo4jå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise e

def get_subgraph_for_visualization(kg_id):
    """è·å–å­å›¾çš„å¯è§†åŒ–æ•°æ®"""
    try:
        safe_kg_id = kg_id.replace('-', '_')
        subgraph_label = f"UserKG_{safe_kg_id}"
        
        graph = Graph("bolt://localhost:7687", auth=("neo4j", "3080neo4j"), secure=False)
        
        # è·å–èŠ‚ç‚¹
        nodes_query = f"""
        MATCH (n:{subgraph_label})
        WHERE n.kg_id = $kg_id
        RETURN n.name as name, labels(n) as labels, properties(n) as props
        LIMIT 100
        """
        
        # è·å–å…³ç³»
        rels_query = f"""
        MATCH (s:{subgraph_label})-[r]->(t:{subgraph_label})
        WHERE r.kg_id = $kg_id
        RETURN s.name as source, t.name as target, type(r) as type, properties(r) as props
        LIMIT 200
        """
        
        nodes_result = graph.run(nodes_query, kg_id=kg_id).data()
        rels_result = graph.run(rels_query, kg_id=kg_id).data()
        
        # æ ¼å¼åŒ–èŠ‚ç‚¹æ•°æ®
        vis_nodes = []
        for node in nodes_result:
            if node['name']:
                # è·å–é™¤å­å›¾æ ‡ç­¾å¤–çš„å…¶ä»–æ ‡ç­¾ä½œä¸ºç±»å‹
                node_labels = [label for label in node['labels'] if not label.startswith('UserKG_')]
                node_type = node_labels[0] if node_labels else 'Unknown'
                
                vis_nodes.append({
                    'id': node['name'],
                    'label': node['name'],
                    'type': node_type,
                    'properties': node['props']
                })
        
        # æ ¼å¼åŒ–å…³ç³»æ•°æ®
        vis_edges = []
        for rel in rels_result:
            if rel['source'] and rel['target']:
                vis_edges.append({
                    'from': rel['source'],
                    'to': rel['target'],
                    'label': rel['type'],
                    'type': rel['type'],
                    'properties': rel['props']
                })
        
        return {
            'nodes': vis_nodes,
            'edges': vis_edges,
            'stats': {
                'nodeCount': len(vis_nodes),
                'edgeCount': len(vis_edges)
            }
        }
        
    except Exception as e:
        print(f"âŒ è·å–å­å›¾å¯è§†åŒ–æ•°æ®å¤±è´¥: {e}")
        return None

def get_subgraph_info(kg_id):
    """è·å–å­å›¾çš„ç»Ÿè®¡ä¿¡æ¯"""
    try:
        safe_kg_id = kg_id.replace('-', '_')
        subgraph_label = f"UserKG_{safe_kg_id}"
        
        graph = Graph("bolt://localhost:7687", auth=("neo4j", "3080neo4j"), secure=False)
        
        # èŠ‚ç‚¹ç»Ÿè®¡
        node_query = f"""
        MATCH (n:{subgraph_label})
        WHERE n.kg_id = $kg_id
        RETURN count(n) as node_count, collect(DISTINCT [label IN labels(n) WHERE NOT label =~ 'UserKG_.*'][0]) as node_types
        """
        
        # å…³ç³»ç»Ÿè®¡
        rel_query = f"""
        MATCH (:{subgraph_label})-[r]->(:{subgraph_label})
        WHERE r.kg_id = $kg_id
        RETURN count(r) as relation_count, collect(DISTINCT type(r)) as relation_types
        """
        
        node_result = graph.run(node_query, kg_id=kg_id).data()
        rel_result = graph.run(rel_query, kg_id=kg_id).data()
        
        if node_result and rel_result:
            # è¿‡æ»¤æ‰Noneå€¼
            node_types = [t for t in node_result[0]["node_types"] if t]
            relation_types = [t for t in rel_result[0]["relation_types"] if t]
            
            return {
                "node_count": node_result[0]["node_count"],
                "relation_count": rel_result[0]["relation_count"],
                "node_types": node_types,
                "relation_types": relation_types,
                "created_time": f"å­å›¾: {subgraph_label}"
            }
        
        return None
        
    except Exception as e:
        print(f"âŒ è·å–å­å›¾ä¿¡æ¯å¤±è´¥: {e}")
        return None

def delete_user_kg_subgraph(kg_id):
    """åˆ é™¤ç”¨æˆ·çš„çŸ¥è¯†å›¾è°±å­å›¾"""
    try:
        safe_kg_id = kg_id.replace('-', '_')
        subgraph_label = f"UserKG_{safe_kg_id}"
        
        graph = Graph("bolt://localhost:7687", auth=("neo4j", "3080neo4j"), secure=False)
        
        # åˆ é™¤å…³ç³»
        rel_delete_query = f"""
        MATCH (s:{subgraph_label})-[r]->(t:{subgraph_label})
        WHERE r.kg_id = $kg_id
        DELETE r
        """
        
        # åˆ é™¤èŠ‚ç‚¹
        node_delete_query = f"""
        MATCH (n:{subgraph_label})
        WHERE n.kg_id = $kg_id
        DELETE n
        """
        
        graph.run(rel_delete_query, kg_id=kg_id)
        graph.run(node_delete_query, kg_id=kg_id)
        
        print(f"âœ… å­å›¾åˆ é™¤æˆåŠŸ: {subgraph_label}")
        return True
        
    except Exception as e:
        print(f"âŒ åˆ é™¤å­å›¾å¤±è´¥: {e}")
        return False

# ==================== æ–‡æ¡£å¤„ç†å‡½æ•° ====================

def read_document_content(file_path):
    """è¯»å–æ–‡æ¡£å†…å®¹"""
    document_text = ""
    
    try:
        if file_path.endswith('.txt'):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    document_text = f.read()
            except UnicodeDecodeError:
                # å°è¯•å…¶ä»–ç¼–ç 
                try:
                    with open(file_path, 'r', encoding='gbk') as f:
                        document_text = f.read()
                except UnicodeDecodeError:
                    with open(file_path, 'r', encoding='latin-1') as f:
                        document_text = f.read()
                        
        elif file_path.endswith('.doc') or file_path.endswith('.docx'):
            # ä½¿ç”¨python-docxåº“è¯»å–Wordæ–‡æ¡£
            doc = docx.Document(file_path)
            document_text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
            
        else:
            raise Exception(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
            
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡æ¡£å¤±è´¥: {file_path} - {e}")
        raise Exception(f"æ— æ³•è¯»å–æ–‡æ¡£: {str(e)}")
    
    if not document_text.strip():
        raise Exception("æ–‡æ¡£å†…å®¹ä¸ºç©º")
    
    print(f"âœ… æˆåŠŸè¯»å–æ–‡æ¡£: {len(document_text)} å­—ç¬¦")
    return document_text

# ==================== ä¸»è¦æ„å»ºå‡½æ•° ====================

def build_knowledge_graph_from_document(file_path, kg_id, kg_name):
    """ä»æ–‡æ¡£æ„å»ºçŸ¥è¯†å›¾è°±çš„ä¸»è¦å‡½æ•°ï¼ˆå­å›¾æ¨¡å¼ï¼‰"""
    try:
        # è¯»å–æ–‡æ¡£å†…å®¹
        document_text = read_document_content(file_path)
        
        if not document_text:
            raise Exception("æ–‡æ¡£å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è¯»å–")
        
        print(f"ğŸ“„ æ–‡æœ¬æ€»é•¿åº¦: {len(document_text)} å­—ç¬¦")
        print(f"ğŸ“ å°†åˆ›å»ºå­å›¾: UserKG_{kg_id.replace('-', '_')}")
        
        # ä¸ºé•¿æ–‡æœ¬åˆ†æ®µå¤„ç†
        chunks = chunk_text(document_text, max_chunk_size=8000, overlap=500)
        all_knowledge_graphs = []
        
        for i, chunk in enumerate(chunks):
            print(f"ğŸ§© å¤„ç†æ–‡æœ¬å— {i+1}/{len(chunks)}ï¼Œé•¿åº¦ï¼š{len(chunk)} å­—ç¬¦")
            print(f"ğŸ“ æ–‡æœ¬å†…å®¹é¢„è§ˆ: {chunk[:100]}...")
            
            # æå–çŸ¥è¯†å›¾è°±ï¼Œå¢åŠ é‡è¯•æœºåˆ¶
            kg = None
            max_retries = 3
            
            for retry in range(max_retries):
                try:
                    print(f"ğŸ”„ å°è¯•æå–çŸ¥è¯†å›¾è°±ï¼Œç¬¬ {retry+1}/{max_retries} æ¬¡")
                    kg = extract_knowledge_graph_from_text(chunk)
                    if kg and kg.nodes:
                        break
                    else:
                        print(f"âš ï¸ ç¬¬ {retry+1} æ¬¡æå–å¤±è´¥ï¼Œé‡è¯•...")
                except Exception as e:
                    print(f"âŒ ç¬¬ {retry+1} æ¬¡æå–å¼‚å¸¸: {e}")
                    if retry == max_retries - 1:
                        print("âŒ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬å›¾è°±")
                        kg = create_enhanced_basic_kg(chunk)
            
            if kg and kg.nodes:
                all_knowledge_graphs.append(kg)
                print(f"âœ… ä»å— {i+1} ä¸­æå–äº† {len(kg.nodes)} ä¸ªèŠ‚ç‚¹å’Œ {len(kg.rels)} ä¸ªå…³ç³»")
                
                # æ‰“å°æå–çš„èŠ‚ç‚¹è¯¦æƒ…
                print("ğŸ“Š æå–çš„èŠ‚ç‚¹:")
                for node in kg.nodes[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    print(f"   - {node.id} ({node.type})")
                if len(kg.nodes) > 5:
                    print(f"   - ... è¿˜æœ‰ {len(kg.nodes)-5} ä¸ªèŠ‚ç‚¹")
                    
                if kg.rels:
                    print("ğŸ”— æå–çš„å…³ç³»:")
                    for rel in kg.rels[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                        print(f"   - {rel.source.id} --{rel.type}--> {rel.target.id}")
                    if len(kg.rels) > 3:
                        print(f"   - ... è¿˜æœ‰ {len(kg.rels)-3} ä¸ªå…³ç³»")
                else:
                    print("ğŸ”— æœªæå–åˆ°å…³ç³»")
            else:
                print(f"âŒ ä»å— {i+1} ä¸­å®Œå…¨æ— æ³•æå–çŸ¥è¯†å›¾è°±")
        
        # åˆå¹¶æ‰€æœ‰çŸ¥è¯†å›¾è°±
        if not all_knowledge_graphs:
            raise Exception("æœªèƒ½ä»æ–‡æ¡£ä¸­æå–æœ‰æ•ˆçš„çŸ¥è¯†å›¾è°±")
            
        merged_kg = merge_knowledge_graphs(all_knowledge_graphs)
        print(f"ğŸ”„ åˆå¹¶åçš„å›¾è°±åŒ…å« {len(merged_kg.nodes)} ä¸ªèŠ‚ç‚¹å’Œ {len(merged_kg.rels)} ä¸ªå…³ç³»")
        
        # å¯¼å…¥Neo4jï¼ˆä½¿ç”¨å­å›¾æ¨¡å¼ï¼‰
        result = import_kg_to_neo4j(merged_kg, None, kg_id)
        
        return {
            'success': True,
            'kg': merged_kg,
            'stats': result,
            'message': 'çŸ¥è¯†å›¾è°±åˆ›å»ºæˆåŠŸ',
            'subgraph': result.get('subgraph')
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'message': f'çŸ¥è¯†å›¾è°±åˆ›å»ºå¤±è´¥: {str(e)}'
        }

# ==================== åŠ è½½çŸ¥è¯†å›¾è°±ä¿¡æ¯å‡½æ•° ====================

def loadKGInfo(kg_id):
    """åŠ è½½çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼ˆç”¨äºå‰ç«¯å…¼å®¹ï¼‰"""
    if kg_id == 'default':
        # è¿”å›é»˜è®¤å›¾è°±ä¿¡æ¯
        try:
            graph = Graph("bolt://localhost:7687", auth=("neo4j", "3080neo4j"), secure=False)
            
            # è·å–é»˜è®¤å›¾è°±ç»Ÿè®¡
            node_query = """
            MATCH (n) 
            WHERE NOT any(label IN labels(n) WHERE label =~ 'UserKG_.*')
            RETURN count(n) as node_count, collect(DISTINCT labels(n)[0]) as node_types
            """
            
            rel_query = """
            MATCH ()-[r]->() 
            WHERE NOT EXISTS(r.kg_id)
            RETURN count(r) as rel_count, collect(DISTINCT type(r)) as rel_types
            """
            
            node_result = graph.run(node_query).data()
            rel_result = graph.run(rel_query).data()
            
            return {
                "kg_id": "default",
                "name": "ç³»ç»Ÿé»˜è®¤å›¾è°±",
                "node_count": node_result[0]["node_count"] if node_result else 0,
                "relation_count": rel_result[0]["rel_count"] if rel_result else 0,
                "node_types": node_result[0]["node_types"] if node_result else [],
                "relation_types": rel_result[0]["rel_types"] if rel_result else [],
                "created_time": "ç³»ç»Ÿé¢„ç½®"
            }
            
        except Exception as e:
            print(f"âŒ è·å–é»˜è®¤å›¾è°±ä¿¡æ¯å¤±è´¥: {e}")
            return None
    else:
        # è¿”å›ç”¨æˆ·å­å›¾ä¿¡æ¯
        return get_subgraph_info(kg_id)